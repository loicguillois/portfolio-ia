{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpxpy in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: lxml in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (4.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gpxpy\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "import glob\n",
    "\n",
    "gpxList = glob.glob('activities/*.gpx')\n",
    "\n",
    "LIMIT = 200\n",
    "for file_path in gpxList:\n",
    "    tree = ET.parse(file_path)\n",
    "\n",
    "    root = tree.getroot()\n",
    "\n",
    "    type = ''\n",
    "    for type_elem in root.findall(\".//{http://www.topografix.com/GPX/1/1}trk/{http://www.topografix.com/GPX/1/1}type\"):\n",
    "        type = type_elem.text\n",
    "\n",
    "    if type == 'running' or type == 'cycling':\n",
    "        y.append(type_elem.text)\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            gpx = gpxpy.parse(f)\n",
    "        points = []\n",
    "        for segment in gpx.tracks[0].segments:\n",
    "            for p in segment.points:\n",
    "                points.append([p.latitude, p.longitude, p.elevation])\n",
    "                if len(points) == LIMIT:\n",
    "                    break\n",
    "\n",
    "        X.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[47.229764, -1.378735],\n",
       " [47.229764, -1.378684],\n",
       " [47.229773, -1.378638],\n",
       " [47.229806, -1.378606],\n",
       " [47.229813, -1.378542],\n",
       " [47.229814, -1.378475],\n",
       " [47.229829, -1.378418],\n",
       " [47.229835, -1.378379],\n",
       " [47.22986, -1.378318],\n",
       " [47.229899, -1.378275],\n",
       " [47.229917, -1.378244],\n",
       " [47.22993, -1.378205],\n",
       " [47.229948, -1.378173],\n",
       " [47.229983, -1.378124],\n",
       " [47.229996, -1.378087],\n",
       " [47.230022, -1.378039],\n",
       " [47.230044, -1.377997],\n",
       " [47.230041, -1.377951],\n",
       " [47.230053, -1.377902],\n",
       " [47.230083, -1.377853],\n",
       " [47.230103, -1.37781],\n",
       " [47.230119, -1.37777],\n",
       " [47.230129, -1.377721],\n",
       " [47.230149, -1.377679],\n",
       " [47.230174, -1.377635],\n",
       " [47.230191, -1.377597],\n",
       " [47.230207, -1.377558],\n",
       " [47.230227, -1.377526],\n",
       " [47.230259, -1.377484],\n",
       " [47.230287, -1.377466],\n",
       " [47.230319, -1.377456],\n",
       " [47.230355, -1.377456],\n",
       " [47.23039, -1.377463],\n",
       " [47.230426, -1.377472],\n",
       " [47.230462, -1.377485],\n",
       " [47.230497, -1.377496],\n",
       " [47.230534, -1.377509],\n",
       " [47.230571, -1.377523],\n",
       " [47.230608, -1.377541],\n",
       " [47.230646, -1.377558],\n",
       " [47.230683, -1.377573],\n",
       " [47.230724, -1.377595],\n",
       " [47.230759, -1.377625],\n",
       " [47.230794, -1.377656],\n",
       " [47.230833, -1.377687],\n",
       " [47.230868, -1.377725],\n",
       " [47.230903, -1.377763],\n",
       " [47.230934, -1.377804],\n",
       " [47.230963, -1.377845],\n",
       " [47.230995, -1.37789],\n",
       " [47.231022, -1.377942],\n",
       " [47.23105, -1.377992],\n",
       " [47.231077, -1.378043],\n",
       " [47.231103, -1.3781],\n",
       " [47.23113, -1.378154],\n",
       " [47.231154, -1.378207],\n",
       " [47.23118, -1.378258],\n",
       " [47.231206, -1.378308],\n",
       " [47.23123, -1.378358],\n",
       " [47.231253, -1.378413],\n",
       " [47.231277, -1.378463],\n",
       " [47.231301, -1.378512],\n",
       " [47.231325, -1.378559],\n",
       " [47.231349, -1.378607],\n",
       " [47.231373, -1.378657],\n",
       " [47.231397, -1.378703],\n",
       " [47.231421, -1.378748],\n",
       " [47.231444, -1.378793],\n",
       " [47.231468, -1.378838],\n",
       " [47.231491, -1.378883],\n",
       " [47.231517, -1.378929],\n",
       " [47.231541, -1.37898],\n",
       " [47.231567, -1.379026],\n",
       " [47.231593, -1.37907],\n",
       " [47.23162, -1.379118],\n",
       " [47.231649, -1.37916],\n",
       " [47.231677, -1.379204],\n",
       " [47.231707, -1.379244],\n",
       " [47.231739, -1.379283],\n",
       " [47.231769, -1.37932],\n",
       " [47.231802, -1.379351],\n",
       " [47.231835, -1.379384],\n",
       " [47.231868, -1.379414],\n",
       " [47.231902, -1.379442],\n",
       " [47.231936, -1.379468],\n",
       " [47.231971, -1.379494],\n",
       " [47.232006, -1.37952],\n",
       " [47.232042, -1.379544],\n",
       " [47.232079, -1.379574],\n",
       " [47.232115, -1.379601],\n",
       " [47.232149, -1.379628],\n",
       " [47.232184, -1.379661],\n",
       " [47.232218, -1.379693],\n",
       " [47.232253, -1.379726],\n",
       " [47.232285, -1.379763],\n",
       " [47.232317, -1.3798],\n",
       " [47.232346, -1.379837],\n",
       " [47.232375, -1.379879],\n",
       " [47.232403, -1.379922],\n",
       " [47.232429, -1.379967],\n",
       " [47.232455, -1.380011],\n",
       " [47.23248, -1.380055],\n",
       " [47.232505, -1.380097],\n",
       " [47.232529, -1.380139],\n",
       " [47.232551, -1.380182],\n",
       " [47.232572, -1.380227],\n",
       " [47.232594, -1.380271],\n",
       " [47.232617, -1.380317],\n",
       " [47.23264, -1.380363],\n",
       " [47.232664, -1.380408],\n",
       " [47.23269, -1.380452],\n",
       " [47.232714, -1.3805],\n",
       " [47.232738, -1.380549],\n",
       " [47.232763, -1.380598],\n",
       " [47.232789, -1.380646],\n",
       " [47.232815, -1.380695],\n",
       " [47.232841, -1.380747],\n",
       " [47.232868, -1.380799],\n",
       " [47.232895, -1.380853],\n",
       " [47.232923, -1.380909],\n",
       " [47.232951, -1.380965],\n",
       " [47.232982, -1.381019],\n",
       " [47.233009, -1.381074],\n",
       " [47.233038, -1.38113],\n",
       " [47.233067, -1.381186],\n",
       " [47.233097, -1.38124],\n",
       " [47.233125, -1.381298],\n",
       " [47.233152, -1.381358],\n",
       " [47.233182, -1.381414],\n",
       " [47.233213, -1.381473],\n",
       " [47.233243, -1.38153],\n",
       " [47.233273, -1.381586],\n",
       " [47.233301, -1.381641],\n",
       " [47.233328, -1.381698],\n",
       " [47.233357, -1.381753],\n",
       " [47.233388, -1.381809],\n",
       " [47.233416, -1.381863],\n",
       " [47.233444, -1.381918],\n",
       " [47.233473, -1.381973],\n",
       " [47.233503, -1.38203],\n",
       " [47.233531, -1.382081],\n",
       " [47.233561, -1.382133],\n",
       " [47.233588, -1.38219],\n",
       " [47.233616, -1.382244],\n",
       " [47.233642, -1.382299],\n",
       " [47.233668, -1.382353],\n",
       " [47.233694, -1.382401],\n",
       " [47.23372, -1.382448],\n",
       " [47.233748, -1.382496],\n",
       " [47.233775, -1.382547],\n",
       " [47.233805, -1.382596],\n",
       " [47.233831, -1.382647],\n",
       " [47.233855, -1.3827],\n",
       " [47.23388, -1.382754],\n",
       " [47.233906, -1.382805],\n",
       " [47.233932, -1.382854],\n",
       " [47.233959, -1.382902],\n",
       " [47.233984, -1.382954],\n",
       " [47.234011, -1.383004],\n",
       " [47.234035, -1.383054],\n",
       " [47.23406, -1.383104],\n",
       " [47.234084, -1.383152],\n",
       " [47.234111, -1.383199],\n",
       " [47.234137, -1.383247],\n",
       " [47.234161, -1.383298],\n",
       " [47.234186, -1.383347],\n",
       " [47.234212, -1.383399],\n",
       " [47.234237, -1.383451],\n",
       " [47.234265, -1.3835],\n",
       " [47.234293, -1.383553],\n",
       " [47.234319, -1.383606],\n",
       " [47.234347, -1.383659],\n",
       " [47.234373, -1.383712],\n",
       " [47.2344, -1.383767],\n",
       " [47.23443, -1.383816],\n",
       " [47.234458, -1.383867],\n",
       " [47.234484, -1.383922],\n",
       " [47.234504, -1.383981],\n",
       " [47.234522, -1.384039],\n",
       " [47.234541, -1.3841],\n",
       " [47.234561, -1.384162],\n",
       " [47.23458, -1.384222],\n",
       " [47.234597, -1.384283],\n",
       " [47.234618, -1.384339],\n",
       " [47.23464, -1.384395],\n",
       " [47.234668, -1.384445],\n",
       " [47.2347, -1.384488],\n",
       " [47.234737, -1.384522],\n",
       " [47.234777, -1.384544],\n",
       " [47.23482, -1.384547],\n",
       " [47.234861, -1.384526],\n",
       " [47.234894, -1.384482],\n",
       " [47.23492, -1.384427],\n",
       " [47.234935, -1.384362],\n",
       " [47.234948, -1.384295],\n",
       " [47.23496, -1.384224],\n",
       " [47.234971, -1.384152],\n",
       " [47.23498, -1.38408],\n",
       " [47.234987, -1.384006],\n",
       " [47.234994, -1.38393],\n",
       " [47.235002, -1.383857],\n",
       " [47.23501, -1.383785],\n",
       " [47.235015, -1.383712],\n",
       " [47.235022, -1.383638],\n",
       " [47.23503, -1.383567],\n",
       " [47.235036, -1.383492],\n",
       " [47.235041, -1.383417],\n",
       " [47.23505, -1.383339],\n",
       " [47.235058, -1.383257],\n",
       " [47.235063, -1.383176],\n",
       " [47.235069, -1.383091],\n",
       " [47.235076, -1.383011],\n",
       " [47.235087, -1.382925],\n",
       " [47.235094, -1.382841],\n",
       " [47.235101, -1.382759],\n",
       " [47.235109, -1.382675],\n",
       " [47.235117, -1.382595],\n",
       " [47.235125, -1.382512],\n",
       " [47.235134, -1.382428],\n",
       " [47.235143, -1.38235],\n",
       " [47.23515, -1.38227],\n",
       " [47.235157, -1.38219],\n",
       " [47.235167, -1.382112],\n",
       " [47.235174, -1.382033],\n",
       " [47.235179, -1.381959],\n",
       " [47.235188, -1.381887],\n",
       " [47.235197, -1.381814],\n",
       " [47.235203, -1.381755],\n",
       " [47.235214, -1.381704],\n",
       " [47.235218, -1.381663],\n",
       " [47.235225, -1.381609],\n",
       " [47.235232, -1.381564],\n",
       " [47.235284, -1.381547],\n",
       " [47.235322, -1.381546],\n",
       " [47.235363, -1.381535],\n",
       " [47.235406, -1.381512],\n",
       " [47.235449, -1.381481],\n",
       " [47.235496, -1.381442],\n",
       " [47.235543, -1.381402],\n",
       " [47.23559, -1.381362],\n",
       " [47.235638, -1.381326],\n",
       " [47.235684, -1.381283],\n",
       " [47.235733, -1.381242],\n",
       " [47.23578, -1.381201],\n",
       " [47.235829, -1.381163],\n",
       " [47.235875, -1.381122],\n",
       " [47.235925, -1.381082],\n",
       " [47.235973, -1.381045],\n",
       " [47.236023, -1.381004],\n",
       " [47.236073, -1.380961],\n",
       " [47.236123, -1.380925],\n",
       " [47.236171, -1.380888],\n",
       " [47.236221, -1.380849],\n",
       " [47.236267, -1.3808],\n",
       " [47.236315, -1.380759],\n",
       " [47.236366, -1.380719],\n",
       " [47.236409, -1.38068],\n",
       " [47.236458, -1.38064],\n",
       " [47.236509, -1.380598],\n",
       " [47.23656, -1.380559],\n",
       " [47.236612, -1.380516],\n",
       " [47.236661, -1.380472],\n",
       " [47.236714, -1.380434],\n",
       " [47.236765, -1.380395],\n",
       " [47.236817, -1.380359],\n",
       " [47.236871, -1.380326],\n",
       " [47.236924, -1.380292],\n",
       " [47.23698, -1.380262],\n",
       " [47.237033, -1.380235],\n",
       " [47.237087, -1.380216],\n",
       " [47.237144, -1.380193],\n",
       " [47.2372, -1.380174],\n",
       " [47.23726, -1.38016],\n",
       " [47.237317, -1.380144],\n",
       " [47.237375, -1.38013],\n",
       " [47.237431, -1.380114],\n",
       " [47.237488, -1.380101],\n",
       " [47.237544, -1.380083],\n",
       " [47.2376, -1.380071],\n",
       " [47.237657, -1.38006],\n",
       " [47.237714, -1.380044],\n",
       " [47.237771, -1.380026],\n",
       " [47.237825, -1.380017],\n",
       " [47.237884, -1.380001],\n",
       " [47.23794, -1.379989],\n",
       " [47.237993, -1.379977],\n",
       " [47.238049, -1.379964],\n",
       " [47.238104, -1.379946],\n",
       " [47.238159, -1.379933],\n",
       " [47.238215, -1.379921],\n",
       " [47.238269, -1.379907],\n",
       " [47.238325, -1.379896],\n",
       " [47.238377, -1.379884],\n",
       " [47.238431, -1.379871],\n",
       " [47.238486, -1.379859],\n",
       " [47.23854, -1.379846],\n",
       " [47.238595, -1.379829],\n",
       " [47.23865, -1.379816],\n",
       " [47.238705, -1.379799],\n",
       " [47.238761, -1.379785],\n",
       " [47.238818, -1.379773],\n",
       " [47.238875, -1.379761],\n",
       " [47.238931, -1.379749],\n",
       " [47.238987, -1.379733],\n",
       " [47.239044, -1.379717],\n",
       " [47.239101, -1.379704],\n",
       " [47.239158, -1.37969],\n",
       " [47.239214, -1.379678],\n",
       " [47.239271, -1.379666],\n",
       " [47.239328, -1.379653],\n",
       " [47.239387, -1.379639],\n",
       " [47.239443, -1.379625],\n",
       " [47.239501, -1.379608],\n",
       " [47.239554, -1.379596],\n",
       " [47.239612, -1.379583],\n",
       " [47.239668, -1.379572],\n",
       " [47.239725, -1.379559],\n",
       " [47.23978, -1.379545],\n",
       " [47.239834, -1.379534],\n",
       " [47.23989, -1.379522],\n",
       " [47.239947, -1.379506],\n",
       " [47.240004, -1.379494],\n",
       " [47.240061, -1.37948],\n",
       " [47.240118, -1.37947],\n",
       " [47.240173, -1.379463],\n",
       " [47.24023, -1.379451],\n",
       " [47.240287, -1.379437],\n",
       " [47.240343, -1.379425],\n",
       " [47.240403, -1.379413],\n",
       " [47.24046, -1.379398],\n",
       " [47.240516, -1.379382],\n",
       " [47.240572, -1.37937],\n",
       " [47.240627, -1.379352],\n",
       " [47.240681, -1.379335],\n",
       " [47.240737, -1.379323],\n",
       " [47.240793, -1.379309],\n",
       " [47.240845, -1.379294],\n",
       " [47.240901, -1.379276],\n",
       " [47.240956, -1.379262],\n",
       " [47.241008, -1.379251],\n",
       " [47.241063, -1.379239],\n",
       " [47.241116, -1.379229],\n",
       " [47.241169, -1.379219],\n",
       " [47.241221, -1.379212],\n",
       " [47.241275, -1.379205],\n",
       " [47.24133, -1.379199],\n",
       " [47.241379, -1.379173],\n",
       " [47.241422, -1.37912],\n",
       " [47.241453, -1.379053],\n",
       " [47.241475, -1.378974],\n",
       " [47.241492, -1.378893],\n",
       " [47.24151, -1.37881],\n",
       " [47.241528, -1.378729],\n",
       " [47.241543, -1.378647],\n",
       " [47.24156, -1.378561],\n",
       " [47.241578, -1.378476],\n",
       " [47.241596, -1.378391],\n",
       " [47.241617, -1.378309],\n",
       " [47.241641, -1.378228],\n",
       " [47.241665, -1.378143],\n",
       " [47.24169, -1.378062],\n",
       " [47.241716, -1.377983],\n",
       " [47.241748, -1.377906],\n",
       " [47.241783, -1.377832],\n",
       " [47.241819, -1.377763],\n",
       " [47.241857, -1.377701],\n",
       " [47.241902, -1.377635],\n",
       " [47.241946, -1.377572],\n",
       " [47.241994, -1.377509],\n",
       " [47.242047, -1.377456],\n",
       " [47.242103, -1.377404],\n",
       " [47.242161, -1.377355],\n",
       " [47.24222, -1.377308],\n",
       " [47.242279, -1.377264],\n",
       " [47.242341, -1.37722],\n",
       " [47.242404, -1.377178],\n",
       " [47.242467, -1.377131],\n",
       " [47.242528, -1.377086],\n",
       " [47.242589, -1.377045],\n",
       " [47.242646, -1.376998],\n",
       " [47.242704, -1.376956],\n",
       " [47.242761, -1.376908],\n",
       " [47.242817, -1.376854],\n",
       " [47.242874, -1.376797],\n",
       " [47.242931, -1.376741],\n",
       " [47.242988, -1.376681],\n",
       " [47.243045, -1.37662],\n",
       " [47.243098, -1.37655],\n",
       " [47.243153, -1.376481],\n",
       " [47.243207, -1.376421],\n",
       " [47.243254, -1.376345],\n",
       " [47.243307, -1.376281],\n",
       " [47.243357, -1.376196],\n",
       " [47.243379, -1.37614],\n",
       " [47.243431, -1.376071],\n",
       " [47.243475, -1.375987],\n",
       " [47.243523, -1.375907],\n",
       " [47.243571, -1.375832],\n",
       " [47.243612, -1.375763],\n",
       " [47.243658, -1.375691],\n",
       " [47.243699, -1.375623],\n",
       " [47.243746, -1.37555],\n",
       " [47.243791, -1.375485],\n",
       " [47.243838, -1.375414],\n",
       " [47.243889, -1.375348],\n",
       " [47.243943, -1.375294],\n",
       " [47.243997, -1.375236],\n",
       " [47.244053, -1.375192],\n",
       " [47.244108, -1.375147],\n",
       " [47.244166, -1.375102],\n",
       " [47.244226, -1.375056],\n",
       " [47.244284, -1.37502],\n",
       " [47.24434, -1.374983],\n",
       " [47.244398, -1.374938],\n",
       " [47.244457, -1.374901],\n",
       " [47.244517, -1.374863],\n",
       " [47.244577, -1.374822],\n",
       " [47.244638, -1.374783],\n",
       " [47.2447, -1.374748],\n",
       " [47.244759, -1.374709],\n",
       " [47.244819, -1.374664],\n",
       " [47.24488, -1.37462],\n",
       " [47.24494, -1.374574],\n",
       " [47.244999, -1.37453],\n",
       " [47.24506, -1.374479],\n",
       " [47.245122, -1.37443],\n",
       " [47.245184, -1.374382],\n",
       " [47.245244, -1.374332],\n",
       " [47.245303, -1.374282],\n",
       " [47.24536, -1.374225],\n",
       " [47.245422, -1.37417],\n",
       " [47.245483, -1.374118],\n",
       " [47.245547, -1.374062],\n",
       " [47.245613, -1.374005],\n",
       " [47.24568, -1.373949],\n",
       " [47.245746, -1.373884],\n",
       " [47.24581, -1.373818],\n",
       " [47.245876, -1.373755],\n",
       " [47.245942, -1.373687],\n",
       " [47.246009, -1.373625],\n",
       " [47.246074, -1.373561],\n",
       " [47.246139, -1.373498],\n",
       " [47.246206, -1.373435],\n",
       " [47.246274, -1.373372],\n",
       " [47.246339, -1.37331],\n",
       " [47.246403, -1.373248],\n",
       " [47.246467, -1.373189],\n",
       " [47.246533, -1.373131],\n",
       " [47.246596, -1.373075],\n",
       " [47.246654, -1.373016],\n",
       " [47.246709, -1.372963],\n",
       " [47.246762, -1.372916],\n",
       " [47.246822, -1.372867],\n",
       " [47.246868, -1.372815],\n",
       " [47.246935, -1.372749],\n",
       " [47.246994, -1.372702],\n",
       " [47.247057, -1.372645],\n",
       " [47.247127, -1.372579],\n",
       " [47.247186, -1.372518],\n",
       " [47.247248, -1.372455],\n",
       " [47.247291, -1.372431],\n",
       " [47.247358, -1.372362],\n",
       " [47.247426, -1.372282],\n",
       " [47.247472, -1.372222],\n",
       " [47.247524, -1.372161],\n",
       " [47.247555, -1.372089],\n",
       " [47.247578, -1.372022],\n",
       " [47.247615, -1.371976],\n",
       " [47.247653, -1.371908],\n",
       " [47.24768, -1.371808],\n",
       " [47.247711, -1.371721],\n",
       " [47.24771, -1.371625],\n",
       " [47.247709, -1.371528],\n",
       " [47.247744, -1.371453],\n",
       " [47.247792, -1.371399],\n",
       " [47.247835, -1.371342],\n",
       " [47.247866, -1.371275],\n",
       " [47.247888, -1.371202],\n",
       " [47.247905, -1.371131],\n",
       " [47.247914, -1.371062],\n",
       " [47.247922, -1.370986],\n",
       " [47.247941, -1.37091],\n",
       " [47.247981, -1.370856],\n",
       " [47.248029, -1.370827],\n",
       " [47.248083, -1.370829],\n",
       " [47.248131, -1.370866],\n",
       " [47.248164, -1.370932],\n",
       " [47.248188, -1.371007],\n",
       " [47.248202, -1.37109],\n",
       " [47.248212, -1.371176],\n",
       " [47.248229, -1.371263],\n",
       " [47.248261, -1.371342],\n",
       " [47.248296, -1.371419],\n",
       " [47.248333, -1.371492],\n",
       " [47.24837, -1.37157],\n",
       " [47.248411, -1.371645],\n",
       " [47.248452, -1.37172],\n",
       " [47.248492, -1.371799],\n",
       " [47.248536, -1.371876],\n",
       " [47.24858, -1.371949],\n",
       " [47.248626, -1.372022],\n",
       " [47.248669, -1.372095],\n",
       " [47.248714, -1.372164],\n",
       " [47.248759, -1.37223],\n",
       " [47.248805, -1.372293],\n",
       " [47.248851, -1.372361],\n",
       " [47.248899, -1.372426],\n",
       " [47.248946, -1.372492],\n",
       " [47.248993, -1.372553],\n",
       " [47.249041, -1.37262],\n",
       " [47.249089, -1.372685],\n",
       " [47.249142, -1.37275],\n",
       " [47.249193, -1.372807],\n",
       " [47.249247, -1.372868],\n",
       " [47.249299, -1.37293],\n",
       " [47.249355, -1.372993],\n",
       " [47.249408, -1.373054],\n",
       " [47.249459, -1.373118],\n",
       " [47.24951, -1.373181],\n",
       " [47.249563, -1.373241],\n",
       " [47.249615, -1.373303],\n",
       " [47.24967, -1.373366],\n",
       " [47.249723, -1.373427],\n",
       " [47.249774, -1.373491],\n",
       " [47.249826, -1.373552],\n",
       " [47.249879, -1.373617],\n",
       " [47.249932, -1.373678],\n",
       " [47.249983, -1.373739],\n",
       " [47.250035, -1.3738],\n",
       " [47.250085, -1.373859],\n",
       " [47.250134, -1.373917],\n",
       " [47.250184, -1.373977],\n",
       " [47.250236, -1.374042],\n",
       " [47.250288, -1.3741],\n",
       " [47.25034, -1.374161],\n",
       " [47.250392, -1.374221],\n",
       " [47.250444, -1.374284],\n",
       " [47.250495, -1.374344],\n",
       " [47.250544, -1.374404],\n",
       " [47.250593, -1.374463],\n",
       " [47.250643, -1.374525],\n",
       " [47.250693, -1.374583],\n",
       " [47.250743, -1.374641],\n",
       " [47.250794, -1.374702],\n",
       " [47.250847, -1.374761],\n",
       " [47.250898, -1.374821],\n",
       " [47.250948, -1.374883],\n",
       " [47.250999, -1.374945],\n",
       " [47.251048, -1.375004],\n",
       " [47.2511, -1.375065],\n",
       " [47.251151, -1.375123],\n",
       " [47.2512, -1.375182],\n",
       " [47.251251, -1.375239],\n",
       " [47.251303, -1.375295],\n",
       " [47.251351, -1.375357],\n",
       " [47.251401, -1.375417],\n",
       " [47.25145, -1.375476],\n",
       " [47.2515, -1.375533],\n",
       " [47.251549, -1.37559],\n",
       " [47.251597, -1.375651],\n",
       " [47.251646, -1.375707],\n",
       " [47.251696, -1.375763],\n",
       " [47.251745, -1.375822],\n",
       " [47.251794, -1.375881],\n",
       " [47.251844, -1.375941],\n",
       " [47.251893, -1.375998],\n",
       " [47.251942, -1.376056],\n",
       " [47.251991, -1.376114],\n",
       " [47.25204, -1.37617],\n",
       " [47.252088, -1.376229],\n",
       " [47.252136, -1.37629],\n",
       " [47.252184, -1.376348],\n",
       " [47.252235, -1.376404],\n",
       " [47.252287, -1.376464],\n",
       " [47.252335, -1.376523],\n",
       " [47.252385, -1.376581],\n",
       " [47.252435, -1.376637],\n",
       " [47.252485, -1.376695],\n",
       " [47.252534, -1.376755],\n",
       " [47.252582, -1.376815],\n",
       " [47.252631, -1.376874],\n",
       " [47.252682, -1.37693],\n",
       " [47.252733, -1.376989],\n",
       " [47.252783, -1.377048],\n",
       " [47.252832, -1.377107],\n",
       " [47.252881, -1.377167],\n",
       " [47.25293, -1.377226],\n",
       " [47.252982, -1.377282],\n",
       " [47.253031, -1.377338],\n",
       " [47.253079, -1.377394],\n",
       " [47.25313, -1.377448],\n",
       " [47.25318, -1.377505],\n",
       " [47.253228, -1.377566],\n",
       " [47.253277, -1.377627],\n",
       " [47.253324, -1.377685],\n",
       " [47.253372, -1.377743],\n",
       " [47.253421, -1.377798],\n",
       " [47.253469, -1.377855],\n",
       " [47.25352, -1.377913],\n",
       " [47.253567, -1.377971],\n",
       " [47.253613, -1.378029],\n",
       " [47.25366, -1.378087],\n",
       " [47.253708, -1.378145],\n",
       " [47.253756, -1.378197],\n",
       " [47.253804, -1.378255],\n",
       " [47.25385, -1.378314],\n",
       " [47.253896, -1.378373],\n",
       " [47.253945, -1.37843],\n",
       " [47.253993, -1.378488],\n",
       " [47.254039, -1.378548],\n",
       " [47.254085, -1.37861],\n",
       " [47.254131, -1.378669],\n",
       " [47.254174, -1.378727],\n",
       " [47.254221, -1.378795],\n",
       " [47.254264, -1.378863],\n",
       " [47.254307, -1.378927],\n",
       " [47.254352, -1.378994],\n",
       " [47.254394, -1.379064],\n",
       " [47.254438, -1.379129],\n",
       " [47.254476, -1.379197],\n",
       " [47.254518, -1.379266],\n",
       " [47.254558, -1.379336],\n",
       " [47.254595, -1.379409],\n",
       " [47.254632, -1.379481],\n",
       " [47.254667, -1.37955],\n",
       " [47.254702, -1.379621],\n",
       " [47.254737, -1.379694],\n",
       " [47.254771, -1.379764],\n",
       " [47.254806, -1.379834],\n",
       " [47.25484, -1.379904],\n",
       " [47.254873, -1.379975],\n",
       " [47.254904, -1.380047],\n",
       " [47.254935, -1.380119],\n",
       " [47.254968, -1.380193],\n",
       " [47.254997, -1.380266],\n",
       " [47.255026, -1.380341],\n",
       " [47.255051, -1.380415],\n",
       " [47.255079, -1.38049],\n",
       " [47.255106, -1.380564],\n",
       " [47.25513, -1.380637],\n",
       " [47.255153, -1.380712],\n",
       " [47.255176, -1.380789],\n",
       " [47.255199, -1.380863],\n",
       " [47.255222, -1.38094],\n",
       " [47.255242, -1.381014],\n",
       " [47.255262, -1.381093],\n",
       " [47.255282, -1.381171],\n",
       " [47.255302, -1.381248],\n",
       " [47.255319, -1.381327],\n",
       " [47.255337, -1.381404],\n",
       " [47.255353, -1.381478],\n",
       " [47.255368, -1.381552],\n",
       " [47.255383, -1.381626],\n",
       " [47.255399, -1.381698],\n",
       " [47.255412, -1.38177],\n",
       " [47.255424, -1.381846],\n",
       " [47.255438, -1.38192],\n",
       " [47.255454, -1.381997],\n",
       " [47.255467, -1.382072],\n",
       " [47.255478, -1.38215],\n",
       " [47.255488, -1.382225],\n",
       " [47.255499, -1.382294],\n",
       " [47.25551, -1.382369],\n",
       " [47.255518, -1.382438],\n",
       " [47.255528, -1.38251],\n",
       " [47.255533, -1.382583],\n",
       " [47.255539, -1.382651],\n",
       " [47.255543, -1.38272],\n",
       " [47.255549, -1.382788],\n",
       " [47.255557, -1.382855],\n",
       " [47.25556, -1.382928],\n",
       " [47.255562, -1.382999],\n",
       " [47.255567, -1.383071],\n",
       " [47.255571, -1.383145],\n",
       " [47.255573, -1.38322],\n",
       " [47.255574, -1.383296],\n",
       " [47.255574, -1.383369],\n",
       " [47.255576, -1.383447],\n",
       " [47.255581, -1.383522],\n",
       " [47.255584, -1.383599],\n",
       " [47.255583, -1.383673],\n",
       " [47.255581, -1.383746],\n",
       " [47.255579, -1.383819],\n",
       " [47.255576, -1.383895],\n",
       " [47.255573, -1.383966],\n",
       " [47.255573, -1.384039],\n",
       " [47.255566, -1.384186],\n",
       " [47.255561, -1.384333],\n",
       " [47.255556, -1.384407],\n",
       " [47.255555, -1.384563],\n",
       " [47.255553, -1.38464],\n",
       " [47.255552, -1.384716],\n",
       " [47.255548, -1.384791],\n",
       " [47.255546, -1.384866],\n",
       " [47.255546, -1.384938],\n",
       " [47.255544, -1.385014],\n",
       " [47.255541, -1.385091],\n",
       " [47.255538, -1.385163],\n",
       " [47.255534, -1.385236],\n",
       " [47.255531, -1.385312],\n",
       " [47.255528, -1.385388],\n",
       " [47.255525, -1.385463],\n",
       " [47.255526, -1.38554],\n",
       " [47.255524, -1.385609],\n",
       " [47.25552, -1.385682],\n",
       " [47.255519, -1.38575],\n",
       " [47.255517, -1.385819],\n",
       " [47.255515, -1.38589],\n",
       " [47.255517, -1.385964],\n",
       " [47.255522, -1.386036],\n",
       " [47.25553, -1.386106],\n",
       " [47.25555, -1.386173],\n",
       " [47.255578, -1.386237],\n",
       " [47.255608, -1.386299],\n",
       " [47.255642, -1.38636],\n",
       " [47.255682, -1.386412],\n",
       " [47.255724, -1.386451],\n",
       " [47.255777, -1.386456],\n",
       " [47.255831, -1.386473],\n",
       " [47.255885, -1.386486],\n",
       " [47.255939, -1.386496],\n",
       " [47.255993, -1.386507],\n",
       " [47.256047, -1.386511],\n",
       " [47.256103, -1.386497],\n",
       " [47.256156, -1.386466],\n",
       " [47.256207, -1.386421],\n",
       " [47.256256, -1.386371],\n",
       " [47.256302, -1.38631],\n",
       " [47.256347, -1.386249],\n",
       " [47.256397, -1.386185],\n",
       " [47.256446, -1.386125],\n",
       " [47.256493, -1.386058],\n",
       " [47.256544, -1.385992],\n",
       " [47.256594, -1.385925],\n",
       " [47.256644, -1.385861],\n",
       " [47.256692, -1.3858],\n",
       " [47.25674, -1.385733],\n",
       " [47.256793, -1.385671],\n",
       " [47.256842, -1.385607],\n",
       " [47.256888, -1.385543],\n",
       " [47.256935, -1.385481],\n",
       " [47.256983, -1.385426],\n",
       " [47.25703, -1.385371],\n",
       " [47.257076, -1.385314],\n",
       " [47.257115, -1.385271],\n",
       " [47.257166, -1.38521],\n",
       " [47.257214, -1.385155],\n",
       " [47.257259, -1.385095],\n",
       " [47.257306, -1.385033],\n",
       " [47.25735, -1.384974],\n",
       " [47.2574, -1.384913],\n",
       " [47.257448, -1.384846],\n",
       " [47.257539, -1.384741],\n",
       " [47.257583, -1.384678],\n",
       " [47.257628, -1.38462],\n",
       " [47.257675, -1.384552],\n",
       " [47.257718, -1.384502],\n",
       " [47.257754, -1.384439],\n",
       " [47.257797, -1.384375],\n",
       " [47.25784, -1.384322],\n",
       " [47.257886, -1.384261],\n",
       " [47.257932, -1.384211],\n",
       " [47.257973, -1.384162],\n",
       " [47.258005, -1.384103],\n",
       " [47.258054, -1.384037],\n",
       " [47.258098, -1.38398],\n",
       " [47.25823, -1.383815],\n",
       " [47.258272, -1.38376],\n",
       " [47.258318, -1.383702],\n",
       " [47.258359, -1.38365],\n",
       " [47.258402, -1.383594],\n",
       " [47.258448, -1.383538],\n",
       " [47.258492, -1.383483],\n",
       " [47.258537, -1.383426],\n",
       " [47.258578, -1.38337],\n",
       " [47.258621, -1.383314],\n",
       " [47.258665, -1.383257],\n",
       " [47.258708, -1.383195],\n",
       " [47.258755, -1.383138],\n",
       " [47.2588, -1.38308],\n",
       " [47.258846, -1.383022],\n",
       " [47.258891, -1.382963],\n",
       " [47.258933, -1.382905],\n",
       " [47.258979, -1.382845],\n",
       " [47.259024, -1.382789],\n",
       " [47.25907, -1.38273],\n",
       " [47.259116, -1.382674],\n",
       " [47.259158, -1.382616],\n",
       " [47.259204, -1.382556],\n",
       " [47.259252, -1.382495],\n",
       " [47.259297, -1.382432],\n",
       " [47.25934, -1.382373],\n",
       " [47.259388, -1.382312],\n",
       " [47.25953, -1.382127],\n",
       " [47.259569, -1.382066],\n",
       " [47.259612, -1.382005],\n",
       " [47.259659, -1.381938],\n",
       " [47.25971, -1.381881],\n",
       " [47.259757, -1.381817],\n",
       " [47.259809, -1.381749],\n",
       " [47.259857, -1.38168],\n",
       " [47.259907, -1.381615],\n",
       " [47.259957, -1.381545],\n",
       " [47.260006, -1.38148],\n",
       " [47.260054, -1.381417],\n",
       " [47.260102, -1.381353],\n",
       " [47.260152, -1.381287],\n",
       " [47.2602, -1.381228],\n",
       " [47.260248, -1.38117],\n",
       " [47.260297, -1.381107],\n",
       " [47.260344, -1.381045],\n",
       " [47.260394, -1.380991],\n",
       " [47.260441, -1.380934],\n",
       " [47.260486, -1.380871],\n",
       " [47.260528, -1.380816],\n",
       " [47.260572, -1.380758],\n",
       " [47.260617, -1.380694],\n",
       " [47.260664, -1.380634],\n",
       " [47.260713, -1.380568],\n",
       " [47.26076, -1.380507],\n",
       " [47.260808, -1.380446],\n",
       " [47.260853, -1.380384],\n",
       " [47.260899, -1.38032],\n",
       " [47.260946, -1.380255],\n",
       " [47.260993, -1.380194],\n",
       " [47.261038, -1.380131],\n",
       " [47.261079, -1.380066],\n",
       " [47.261123, -1.379995],\n",
       " [47.261166, -1.379926],\n",
       " [47.26121, -1.379852],\n",
       " [47.261249, -1.37978],\n",
       " [47.261287, -1.379701],\n",
       " [47.261325, -1.379626],\n",
       " [47.261359, -1.379545],\n",
       " [47.261394, -1.379469],\n",
       " [47.261428, -1.379391],\n",
       " [47.261462, -1.379308],\n",
       " [47.261495, -1.379232],\n",
       " [47.261529, -1.379152],\n",
       " [47.261564, -1.379075],\n",
       " [47.261599, -1.378991],\n",
       " [47.26163, -1.378909],\n",
       " [47.261663, -1.378828],\n",
       " [47.261695, -1.378747],\n",
       " [47.261727, -1.378668],\n",
       " [47.261761, -1.378584],\n",
       " [47.261795, -1.378504],\n",
       " [47.261826, -1.378425],\n",
       " [47.26186, -1.378346],\n",
       " [47.261891, -1.378269],\n",
       " [47.26192, -1.378185],\n",
       " [47.261956, -1.378101],\n",
       " [47.261994, -1.378014],\n",
       " [47.262022, -1.377958],\n",
       " [47.262062, -1.377882],\n",
       " [47.262093, -1.377803],\n",
       " [47.262127, -1.377723],\n",
       " [47.262152, -1.377646],\n",
       " [47.262186, -1.37758],\n",
       " [47.262219, -1.377507],\n",
       " [47.262253, -1.37743],\n",
       " [47.262288, -1.377369],\n",
       " [47.262326, -1.377287],\n",
       " [47.262357, -1.377208],\n",
       " [47.262385, -1.377123],\n",
       " [47.262414, -1.377046],\n",
       " [47.262449, -1.376971],\n",
       " [47.262485, -1.376897],\n",
       " [47.262512, -1.376824],\n",
       " [47.262536, -1.376761],\n",
       " [47.262564, -1.376689],\n",
       " [47.262597, -1.376621],\n",
       " [47.262625, -1.376547],\n",
       " [47.262656, -1.37648],\n",
       " [47.262687, -1.376399],\n",
       " [47.262718, -1.376306],\n",
       " [47.262753, -1.376236],\n",
       " [47.262782, -1.376171],\n",
       " [47.262816, -1.376089],\n",
       " [47.262838, -1.376012],\n",
       " [47.262842, -1.37592],\n",
       " [47.262844, -1.375831],\n",
       " [47.262823, -1.375758],\n",
       " [47.262786, -1.375685],\n",
       " [47.262751, -1.375619],\n",
       " [47.262709, -1.375556],\n",
       " [47.262662, -1.375492],\n",
       " [47.26262, -1.375429],\n",
       " [47.262581, -1.37536],\n",
       " [47.262536, -1.375294],\n",
       " [47.262493, -1.375234],\n",
       " [47.262452, -1.375172],\n",
       " [47.262412, -1.375108],\n",
       " [47.262372, -1.375044],\n",
       " [47.262333, -1.374996],\n",
       " [47.262292, -1.374929],\n",
       " [47.262253, -1.374867],\n",
       " [47.262215, -1.374807],\n",
       " [47.262177, -1.374764],\n",
       " [47.262143, -1.374716],\n",
       " [47.262104, -1.374665],\n",
       " [47.262069, -1.374604],\n",
       " [47.26202, -1.374566],\n",
       " [47.261974, -1.374524],\n",
       " [47.261929, -1.374464],\n",
       " [47.26188, -1.374422],\n",
       " [47.261834, -1.37438],\n",
       " [47.261787, -1.374328],\n",
       " [47.261738, -1.374242],\n",
       " [47.261696, -1.374191],\n",
       " [47.261654, -1.374133],\n",
       " [47.261617, -1.37407],\n",
       " [47.261586, -1.374013],\n",
       " [47.261537, -1.373953],\n",
       " [47.261493, -1.373896],\n",
       " [47.261458, -1.373832],\n",
       " [47.261425, -1.373752],\n",
       " [47.26139, -1.37369],\n",
       " [47.261362, -1.373634],\n",
       " [47.261318, -1.373594],\n",
       " [47.261261, -1.373541],\n",
       " [47.261201, -1.373498],\n",
       " [47.261175, -1.373448],\n",
       " [47.261142, -1.37341],\n",
       " [47.261102, -1.373369],\n",
       " [47.261051, -1.373327],\n",
       " [47.26099, -1.373288],\n",
       " [47.260934, -1.373256],\n",
       " [47.260884, -1.373206],\n",
       " [47.260836, -1.373156],\n",
       " [47.260787, -1.373119],\n",
       " [47.260741, -1.373075],\n",
       " [47.260697, -1.373038],\n",
       " [47.260654, -1.373003],\n",
       " [47.260607, -1.372963],\n",
       " [47.260563, -1.37292],\n",
       " [47.260517, -1.372879],\n",
       " [47.260461, -1.372834],\n",
       " [47.260406, -1.372788],\n",
       " [47.260359, -1.372734],\n",
       " [47.260315, -1.372685],\n",
       " [47.260273, -1.372639],\n",
       " [47.260229, -1.372588],\n",
       " [47.260189, -1.372542],\n",
       " [47.260146, -1.372493],\n",
       " [47.260106, -1.37244],\n",
       " [47.260064, -1.372389],\n",
       " [47.260024, -1.372343],\n",
       " [47.259981, -1.372281],\n",
       " [47.259951, -1.372223],\n",
       " [47.259914, -1.372174],\n",
       " [47.259882, -1.372127],\n",
       " [47.259858, -1.372084],\n",
       " [47.2598, -1.372055],\n",
       " [47.259734, -1.372022],\n",
       " [47.259685, -1.371985],\n",
       " [47.259625, -1.371957],\n",
       " [47.259557, -1.371858],\n",
       " [47.259495, -1.371795],\n",
       " [47.259453, -1.371731],\n",
       " [47.259413, -1.371669],\n",
       " [47.259376, -1.371615],\n",
       " [47.259347, -1.371554],\n",
       " [47.259308, -1.371501],\n",
       " [47.259281, -1.371434],\n",
       " [47.259249, -1.371378],\n",
       " [47.259184, -1.371308],\n",
       " [47.259134, -1.371244],\n",
       " [47.259081, -1.37118],\n",
       " [47.259045, -1.371128],\n",
       " [47.258999, -1.371078],\n",
       " [47.258957, -1.371029],\n",
       " [47.258918, -1.370974],\n",
       " [47.258887, -1.370926],\n",
       " [47.258818, -1.370874],\n",
       " [47.258773, -1.370824],\n",
       " [47.258729, -1.370779],\n",
       " [47.258677, -1.37073],\n",
       " [47.258641, -1.370719],\n",
       " [47.258618, -1.370656],\n",
       " [47.258589, -1.370616],\n",
       " [47.258557, -1.370562],\n",
       " [47.258514, -1.370505],\n",
       " [47.258471, -1.370449],\n",
       " [47.258439, -1.370396],\n",
       " [47.258402, -1.370358],\n",
       " [47.258377, -1.370306],\n",
       " [47.258346, -1.370257],\n",
       " [47.258307, -1.370205],\n",
       " [47.258266, -1.370166],\n",
       " [47.258172, -1.37011],\n",
       " [47.258102, -1.370065],\n",
       " [47.25806, -1.370022],\n",
       " [47.258024, -1.369967],\n",
       " [47.257989, -1.369927],\n",
       " [47.257951, -1.369881],\n",
       " [47.257913, -1.369838],\n",
       " [47.257866, -1.369785],\n",
       " [47.25782, -1.369725],\n",
       " [47.257782, -1.369682],\n",
       " ...]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/45/s9n1gyr93d511pxxmdwy5rqc0000gn/T/ipykernel_13176/1959684346.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_array = pad_sequences(np.array(X), padding='post', dtype='float32')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_array = pad_sequences(np.array(X), padding='post', dtype='float32')\n",
    "y_array = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47.229763, -1.378735],\n",
       "       [47.229763, -1.378684],\n",
       "       [47.229774, -1.378638],\n",
       "       ...,\n",
       "       [ 0.      ,  0.      ],\n",
       "       [ 0.      ,  0.      ],\n",
       "       [ 0.      ,  0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Nous devons appliquer le scaler à chaque séquence individuellement\n",
    "X_array = np.array([scaler.fit_transform(sequence) for sequence in X_array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Codage à chaud des labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_array)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Diviser les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Construire le modèle\n",
    "model = Sequential([\n",
    "    LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh'),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 13:59:06.628108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 13:59:06.777057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=8, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predicted = model.predict(X_test)\n",
    "idx = 0\n",
    "X_begin = scaler.inverse_transform(X_test[idx])\n",
    "X_end = scaler.inverse_transform(X_predicted[idx])\n",
    "X_real_end = scaler.inverse_transform(y_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 13:53:53.812787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 13:53:53.882874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 131ms/step - loss: 0.6159 - accuracy: 0.5926\n",
      "Loss: 0.6158605217933655, Accuracy: 0.5925925970077515\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Construire le modèle\n",
    "model = Sequential([\n",
    "    LSTM(16, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh',return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(16, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(32),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 14:17:35.659185: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 14:17:35.933651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 14:17:36.267628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 14:17:36.715213: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 14:17:37.398324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 13s 129ms/step - loss: 0.6740 - accuracy: 0.5651\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.6531 - accuracy: 0.6394\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.6261 - accuracy: 0.6487\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.6207 - accuracy: 0.6338\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.6180 - accuracy: 0.6636\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.6039 - accuracy: 0.6506\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.6175 - accuracy: 0.6506\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.5829 - accuracy: 0.6933\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.5583 - accuracy: 0.7026\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 7s 104ms/step - loss: 0.5580 - accuracy: 0.7175\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.5463 - accuracy: 0.7082\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.5422 - accuracy: 0.7138\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.5403 - accuracy: 0.7100\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.5268 - accuracy: 0.7212\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.5482 - accuracy: 0.7138\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.5195 - accuracy: 0.7175\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.5356 - accuracy: 0.7230\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.5201 - accuracy: 0.7119\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.5346 - accuracy: 0.7249\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 7s 104ms/step - loss: 0.5379 - accuracy: 0.7230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x301075640>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=8, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten, MaxPooling1D\n",
    "\n",
    "# Construire le modèle\n",
    "model = Sequential([\n",
    "    LSTM(16, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh',return_sequences=True),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(32),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 14:23:49.412791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 14:23:49.575876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-19 14:23:50.000115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 11s 65ms/step - loss: 0.6383 - accuracy: 0.6357\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.5318 - accuracy: 0.7193\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.5162 - accuracy: 0.7528\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.4707 - accuracy: 0.7695\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.4767 - accuracy: 0.7546\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.4382 - accuracy: 0.7844\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.4141 - accuracy: 0.7900\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.4083 - accuracy: 0.8067\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3690 - accuracy: 0.8327\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.3627 - accuracy: 0.8178\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3323 - accuracy: 0.8439\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3212 - accuracy: 0.8625\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.3064 - accuracy: 0.8662\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.3014 - accuracy: 0.8792\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.2806 - accuracy: 0.8959\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.2715 - accuracy: 0.8829\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.2665 - accuracy: 0.8810\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.2642 - accuracy: 0.8810\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.2570 - accuracy: 0.8810\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.2444 - accuracy: 0.8810\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.2268 - accuracy: 0.9052\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.2211 - accuracy: 0.9071\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.2255 - accuracy: 0.9033\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 8s 57ms/step - loss: 0.1912 - accuracy: 0.9089\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1955 - accuracy: 0.9089\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1984 - accuracy: 0.8996\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1989 - accuracy: 0.9145\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1684 - accuracy: 0.9257\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1676 - accuracy: 0.9294\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1645 - accuracy: 0.9312\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1435 - accuracy: 0.9424\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1439 - accuracy: 0.9498\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1404 - accuracy: 0.9424\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.1498 - accuracy: 0.9405\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1549 - accuracy: 0.9387\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1485 - accuracy: 0.9405\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1127 - accuracy: 0.9535\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1083 - accuracy: 0.9554\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.1569 - accuracy: 0.9405\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1139 - accuracy: 0.9647\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1404 - accuracy: 0.9461\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1357 - accuracy: 0.9442\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1004 - accuracy: 0.9591\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.1058 - accuracy: 0.9647\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1004 - accuracy: 0.9480\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.0980 - accuracy: 0.9703\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 8s 59ms/step - loss: 0.0531 - accuracy: 0.9833\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.1054 - accuracy: 0.9554\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.0879 - accuracy: 0.9721\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 0.0835 - accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x37ddfdfa0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "import glob\n",
    "\n",
    "gpxList = glob.glob('activities/*.gpx')\n",
    "\n",
    "for file_path in gpxList:\n",
    "    tree = ET.parse(file_path)\n",
    "\n",
    "    root = tree.getroot()\n",
    "\n",
    "    type = ''\n",
    "    for type_elem in root.findall(\".//{http://www.topografix.com/GPX/1/1}trk/{http://www.topografix.com/GPX/1/1}type\"):\n",
    "        type = type_elem.text\n",
    "\n",
    "    if type == 'cycling':\n",
    "        y.append(type_elem.text)\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            gpx = gpxpy.parse(f)\n",
    "        points = []\n",
    "        for segment in gpx.tracks[0].segments:\n",
    "            for p in segment.points:\n",
    "                points.append([p.latitude, p.longitude])\n",
    "\n",
    "        X.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(array):\n",
    "    return len(array) < 500\n",
    "\n",
    "filtered = [arr for arr in X if len(arr) > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = [point for trajectory in X for point in trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "scaled_data_restructured = []\n",
    "\n",
    "for trajectory in X:\n",
    "    length = len(trajectory)\n",
    "    scaled_trajectory = scaled_data[index:index+length]\n",
    "    scaled_data_restructured.append(scaled_trajectory)\n",
    "    index += length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = []\n",
    "y_array = []\n",
    "\n",
    "for track in scaled_data_restructured:\n",
    "    if len(track) >= 500:\n",
    "        # X_array.append(track[:250]) # [:250]\n",
    "        # y_array.append(track[250:250+124]) # [250:500]\n",
    "        X_array.append(track[:250]) # [:250]\n",
    "        y_array.append(track[249:249+61]) # [250:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_44 (LSTM)              (None, 250, 50)           10600     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 250, 50)           0         \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 250, 100)         40400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 250, 100)          0         \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 250, 2)           202       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,202\n",
      "Trainable params: 51,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, TimeDistributed, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50, batch_input_shape=(None, 250, 2),return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=50, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(LSTM(units=50,return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(TimeDistributed(Dense(2, activation='linear')))\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:02:46.624018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:02:47.052199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:02:47.303225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:02:47.316668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:02:47.883960: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:02:47.905402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:02:48.590778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/loicguillois/Downloads/export_1817799/test.ipynb Cellule 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/loicguillois/Downloads/export_1817799/test.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test,y_test))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:956\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    954\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    955\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m--> 956\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    958\u001b[0m   \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=50, batch_size=8, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0,41 avec 250 premiers points et 250 suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_13 (Conv1D)          (None, 248, 64)           448       \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 124, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 122, 128)          24704     \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 61, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_56 (LSTM)              (None, 61, 50)            35800     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 61, 50)            0         \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 61, 100)          40400     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 61, 100)           0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 61, 20)            2020      \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 61, 20)            0         \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 61, 2)            42        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,414\n",
      "Trainable params: 103,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional,Conv1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Couche de convolution\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='tanh', input_shape=(250, 2)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='tanh', input_shape=(250, 2)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Couches LSTM\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=50, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=20, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Couche de sortie\n",
    "model.add(TimeDistributed(Dense(2, activation='linear')))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:33:59.754676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:00.255741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:00.495454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:00.509332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:01.099524: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:01.120690: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:01.619612: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 201.5658 - accuracy: 0.9752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:34:07.427833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:07.646130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:07.837216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 16:34:07.847045: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 11s 195ms/step - loss: 201.5658 - accuracy: 0.9752 - val_loss: 200.5976 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 3s 87ms/step - loss: 200.2043 - accuracy: 1.0000 - val_loss: 199.7888 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 199.5280 - accuracy: 1.0000 - val_loss: 199.1163 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 199.0118 - accuracy: 1.0000 - val_loss: 198.6172 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 198.5832 - accuracy: 1.0000 - val_loss: 198.1816 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 198.1692 - accuracy: 1.0000 - val_loss: 197.7681 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 197.7724 - accuracy: 1.0000 - val_loss: 197.3652 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 197.3727 - accuracy: 1.0000 - val_loss: 196.9682 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 196.9780 - accuracy: 1.0000 - val_loss: 196.5727 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 196.5742 - accuracy: 1.0000 - val_loss: 196.1855 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 196.1706 - accuracy: 1.0000 - val_loss: 195.7868 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 195.7773 - accuracy: 1.0000 - val_loss: 195.3951 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 195.3784 - accuracy: 1.0000 - val_loss: 194.9968 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 194.9818 - accuracy: 1.0000 - val_loss: 194.6077 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 194.5894 - accuracy: 1.0000 - val_loss: 194.2182 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 194.1944 - accuracy: 1.0000 - val_loss: 193.8339 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 193.7943 - accuracy: 1.0000 - val_loss: 193.4299 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 193.4001 - accuracy: 1.0000 - val_loss: 193.0507 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 193.0037 - accuracy: 1.0000 - val_loss: 192.6476 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 192.6094 - accuracy: 1.0000 - val_loss: 192.2589 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 192.2145 - accuracy: 1.0000 - val_loss: 191.8783 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 191.8141 - accuracy: 1.0000 - val_loss: 191.4825 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 191.4182 - accuracy: 1.0000 - val_loss: 191.0865 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 191.0266 - accuracy: 1.0000 - val_loss: 190.7014 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 190.6323 - accuracy: 1.0000 - val_loss: 190.3128 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 190.2344 - accuracy: 1.0000 - val_loss: 189.9092 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 189.8415 - accuracy: 1.0000 - val_loss: 189.5276 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 189.4500 - accuracy: 1.0000 - val_loss: 189.1321 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 189.0525 - accuracy: 1.0000 - val_loss: 188.7500 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 188.6624 - accuracy: 1.0000 - val_loss: 188.3685 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 188.2673 - accuracy: 1.0000 - val_loss: 187.9668 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 187.8738 - accuracy: 1.0000 - val_loss: 187.5813 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 187.4772 - accuracy: 1.0000 - val_loss: 187.1972 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 187.0856 - accuracy: 1.0000 - val_loss: 186.8015 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 186.6891 - accuracy: 1.0000 - val_loss: 186.4100 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 186.2961 - accuracy: 1.0000 - val_loss: 186.0173 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 185.8987 - accuracy: 1.0000 - val_loss: 185.6264 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 185.5110 - accuracy: 1.0000 - val_loss: 185.2435 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 185.1147 - accuracy: 1.0000 - val_loss: 184.8484 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 184.7254 - accuracy: 1.0000 - val_loss: 184.4575 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 184.3292 - accuracy: 1.0000 - val_loss: 184.0738 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 183.9390 - accuracy: 1.0000 - val_loss: 183.6788 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 183.5421 - accuracy: 1.0000 - val_loss: 183.2940 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 183.1554 - accuracy: 1.0000 - val_loss: 182.9041 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 182.7589 - accuracy: 1.0000 - val_loss: 182.5203 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 182.3647 - accuracy: 1.0000 - val_loss: 182.1264 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 181.9717 - accuracy: 1.0000 - val_loss: 181.7366 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 181.5798 - accuracy: 1.0000 - val_loss: 181.3415 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 181.1914 - accuracy: 1.0000 - val_loss: 180.9606 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 180.7923 - accuracy: 1.0000 - val_loss: 180.5744 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 180.4017 - accuracy: 1.0000 - val_loss: 180.1794 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 180.0109 - accuracy: 1.0000 - val_loss: 179.7924 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 179.6175 - accuracy: 1.0000 - val_loss: 179.4091 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 179.2245 - accuracy: 1.0000 - val_loss: 179.0181 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 178.8290 - accuracy: 1.0000 - val_loss: 178.6263 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 178.4399 - accuracy: 1.0000 - val_loss: 178.2336 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 178.0496 - accuracy: 1.0000 - val_loss: 177.8524 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 177.6485 - accuracy: 1.0000 - val_loss: 177.4500 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 177.2653 - accuracy: 1.0000 - val_loss: 177.0646 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 176.8710 - accuracy: 1.0000 - val_loss: 176.6754 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 176.4811 - accuracy: 1.0000 - val_loss: 176.2854 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 176.0876 - accuracy: 1.0000 - val_loss: 175.9103 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 175.6954 - accuracy: 1.0000 - val_loss: 175.5061 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 175.3050 - accuracy: 1.0000 - val_loss: 175.1272 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 174.9083 - accuracy: 1.0000 - val_loss: 174.7347 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 174.5141 - accuracy: 1.0000 - val_loss: 174.3487 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 174.1244 - accuracy: 1.0000 - val_loss: 173.9561 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 173.7361 - accuracy: 1.0000 - val_loss: 173.5771 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 173.3416 - accuracy: 1.0000 - val_loss: 173.1805 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 172.9506 - accuracy: 1.0000 - val_loss: 172.7970 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 172.5550 - accuracy: 1.0000 - val_loss: 172.4024 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 172.1707 - accuracy: 1.0000 - val_loss: 172.0077 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 171.7763 - accuracy: 1.0000 - val_loss: 171.6336 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 171.3850 - accuracy: 1.0000 - val_loss: 171.2320 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 170.9939 - accuracy: 1.0000 - val_loss: 170.8586 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 170.6008 - accuracy: 1.0000 - val_loss: 170.4658 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 170.2083 - accuracy: 1.0000 - val_loss: 170.0732 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 169.8179 - accuracy: 1.0000 - val_loss: 169.6874 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 169.4256 - accuracy: 1.0000 - val_loss: 169.2946 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 169.0316 - accuracy: 1.0000 - val_loss: 168.9106 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 168.6413 - accuracy: 1.0000 - val_loss: 168.5149 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 168.2491 - accuracy: 1.0000 - val_loss: 168.1249 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 167.8600 - accuracy: 1.0000 - val_loss: 167.7383 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 167.4653 - accuracy: 1.0000 - val_loss: 167.3482 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 167.0728 - accuracy: 1.0000 - val_loss: 166.9560 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 166.6811 - accuracy: 1.0000 - val_loss: 166.5776 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 166.2930 - accuracy: 1.0000 - val_loss: 166.1803 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 165.8986 - accuracy: 1.0000 - val_loss: 165.7937 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 165.5092 - accuracy: 1.0000 - val_loss: 165.4020 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 165.1116 - accuracy: 1.0000 - val_loss: 165.0116 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 164.7227 - accuracy: 1.0000 - val_loss: 164.6312 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 164.3330 - accuracy: 1.0000 - val_loss: 164.2427 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 163.9418 - accuracy: 1.0000 - val_loss: 163.8503 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 163.5424 - accuracy: 1.0000 - val_loss: 163.4635 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 163.1588 - accuracy: 1.0000 - val_loss: 163.0809 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 162.7623 - accuracy: 1.0000 - val_loss: 162.6829 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 162.3757 - accuracy: 1.0000 - val_loss: 162.3026 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 161.9851 - accuracy: 1.0000 - val_loss: 161.9056 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 161.5923 - accuracy: 1.0000 - val_loss: 161.5237 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 161.1993 - accuracy: 1.0000 - val_loss: 161.1263 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=100, batch_size=8, validation_data=(X_test,y_test))\n",
    "\n",
    "# 0.6918 avec relu\n",
    "# 0.7427 avec tanh\n",
    "# pas mieux avec dim=100 pour lstm\n",
    "\n",
    "#https://www.sciencedirect.com/science/article/pii/S092523122100134X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graphique pour l'accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Graphique pour la loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 17:06:49.797407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 17:06:49.985238: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 17:06:50.109405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-20 17:06:50.119272: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 197ms/step\n"
     ]
    }
   ],
   "source": [
    "X_predicted = model.predict(X_test)\n",
    "idx = 50\n",
    "X_begin = scaler.inverse_transform(X_test[idx])\n",
    "X_end = scaler.inverse_transform(X_predicted[idx])\n",
    "X_real_end = scaler.inverse_transform(y_test[idx])\n",
    "\n",
    "# X_begin = X_test[idx]\n",
    "# X_end = X_predicted[idx]\n",
    "# X_real_end = y_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-379.50471112,  234.42385888]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform([[42,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium\n",
      "  Downloading folium-0.14.0-py2.py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.3/102.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.9 in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from folium) (1.22.4)\n",
      "Collecting branca>=0.6.0\n",
      "  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from folium) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from requests->folium) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from requests->folium) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from requests->folium) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/loicguillois/miniforge3/lib/python3.9/site-packages (from requests->folium) (2022.9.14)\n",
      "Installing collected packages: branca, folium\n",
      "Successfully installed branca-0.6.0 folium-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Créer une carte centrée autour du premier point du chemin\n",
    "m = folium.Map(location=X_end[0], zoom_start=14)\n",
    "\n",
    "# Ajouter une ligne pour le chemin parcouru\n",
    "folium.PolyLine(X_begin, color=\"green\", weight=2.5, opacity=1).add_to(m)\n",
    "folium.PolyLine(X_end, color=\"blue\", weight=2.5, opacity=1).add_to(m)\n",
    "folium.PolyLine(X_real_end, color=\"red\", weight=2.5, opacity=1).add_to(m)\n",
    "\n",
    "# Afficher la carte\n",
    "m.save('chemin_parcouru.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
